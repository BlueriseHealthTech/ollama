steps:
  # --- Build da Imagem (Isso vai demorar uns 5-10 min por causa do download dos modelos) ---
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        docker build -t gcr.io/$PROJECT_ID/ollama-custom:$COMMIT_SHA \
                     -t gcr.io/$PROJECT_ID/ollama-custom:latest .
    timeout: 2400s # 40 minutos de limite (segurança para downloads lentos)

  # --- Push para o Registry ---
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/ollama-custom:$COMMIT_SHA']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/ollama-custom:latest']

  # --- Deploy no Cloud Run ---
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'services'
      - 'update'
      - 'ollama-service' # Nome do seu serviço
      - '--image=gcr.io/$PROJECT_ID/ollama-custom:$COMMIT_SHA'
      - '--region=us-east4'
      - '--ingress=internal' # Mantém seguro (só backend acessa)
      - '--cpu=4' # Ollama precisa de CPU para responder rápido
      - '--memory=8Gi' # Modelos 7b precisam de memória
      - '--no-cpu-throttling' # Importante para performance de IA
      - '--min-instances=0' # Escala a zero para economizar
      - '--max-instances=5'

images:
  - 'gcr.io/$PROJECT_ID/ollama-custom:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/ollama-custom:latest'

timeout: 3600s