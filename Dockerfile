FROM ollama/ollama:latest

# Build Arguments
ARG ENV=development
ARG OLLAMA_MODELS=qwen3:4b

# Labels para identifica√ß√£o
LABEL environment="${ENV}"
LABEL maintainer="BlueRise"
LABEL description="Ollama container customizado para multi-ambientes"

# 1. Vari√°veis para o momento do BUILD
ENV OLLAMA_HOST=0.0.0.0:11434
ENV ENVIRONMENT=${ENV}

# 2. "Assando" os modelos na imagem
# Usamos nohup para garantir que o servidor n√£o morra enquanto baixamos
RUN nohup bash -c "ollama serve &" && \
    sleep 10 && \
    echo "üî¥ Baixando modelos para ambiente: ${ENV}..." && \
    IFS=',' read -ra MODELS <<< "$OLLAMA_MODELS" && \
    for model in "${MODELS[@]}"; do \
        echo "üì¶ Baixando modelo: $model" && \
        ollama pull "$model"; \
    done && \
    echo "‚úÖ Todos os modelos foram baixados com sucesso!" && \
    sleep 5

# 3. Configura√ß√£o de Runtime (Cloud Run)
ENV OLLAMA_KEEP_ALIVE=24h

# 4. Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# ‚ö†Ô∏è O PULO DO GATO:
# For√ßa o Ollama a escutar na porta injetada pelo Cloud Run
ENTRYPOINT ["/bin/sh", "-c", "export OLLAMA_HOST=0.0.0.0:${PORT:-11434} && echo 'üöÄ Ollama iniciando no ambiente: ${ENVIRONMENT}' && echo 'üåê Porta: ${PORT:-11434}' && exec ollama serve"]
