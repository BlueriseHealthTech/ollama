FROM ollama/ollama:latest

# --- 1. O SEGREDO DA PERSIST√äNCIA ---
# Alteramos o local onde os modelos s√£o salvos para uma pasta que N√ÉO √© um Volume.
# O padr√£o (/root/.ollama) √© deletado ap√≥s o build. Este novo caminho (/models) ser√° salvo.
ENV OLLAMA_MODELS="/models"

# Cria a pasta e d√° permiss√£o
RUN mkdir -p /models && chmod 777 /models

# Argumentos de Build
ARG ENV=development
ARG MODELS_LIST="qwen3:4b" 
# Nota: qwen3 ainda n√£o √© oficial na library padr√£o, ajustei para qwen2.5 ou use o nome exato se for custom

LABEL environment="${ENV}"

# --- 2. BAIXANDO OS MODELOS (COOKING) ---
# Iniciamos o servidor em background, esperamos ele subir, baixamos e depois matamos o processo.
RUN bash -c 'nohup ollama serve > /dev/null 2>&1 & \
    PID=$! && \
    sleep 5 && \
    echo "üî¥ Iniciando download dos modelos em $OLLAMA_MODELS..." && \
    ollama pull '"$MODELS_LIST"' && \
    echo "‚úÖ Download conclu√≠do!" && \
    kill $PID'

# --- 3. CONFIGURA√á√ÉO DE RUNTIME ---
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_KEEP_ALIVE=24h

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:11434/api/tags || exit 1

# Entrypoint - OLLAMA_MODELS j√° est√° setado l√° em cima, ent√£o ele vai achar os arquivos.
ENTRYPOINT ["/bin/sh", "-c", "export OLLAMA_HOST=0.0.0.0:${PORT:-11434} && exec ollama serve"]